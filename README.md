

---

# EMODEPICTOR: HARNESSING EMOTIONS FROM AUDIO

## Introduction
Welcome to EMODEPICTOR, a project focused on Speech Emotion Recognition (SER) aimed at automatically classifying and understanding emotional nuances embedded in audio signals. This README provides an overview of the project, including its objectives, methodology, results, and future directions.

## Objective
The primary goal of EMODEPICTOR is to develop intelligent systems capable of perceiving and responding to human emotions in spoken language. This capability has broad applications, including customer service enhancement and adaptive learning experiences in education.

## Methodology
EMODEPICTOR employs a multi-model approach utilizing Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), and Support Vector Machines (SVMs). Each model type contributes unique strengths, with CNNs specializing in spatial feature extraction, RNNs adept at capturing temporal dependencies, and SVMs providing a robust classification framework.

### Data Description
The project utilizes the RAVDESS dataset, featuring over 1,400 audio clips contributed by professional actors, spanning diverse emotional categories.
Link for Dataset:https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio/

### Flowchart of the Project
A flowchart illustrates the sequential steps involved in data exploration, preprocessing, feature extraction, model development, and evaluation.

### Methodology for Emotion Classification from Audio Data
The methodology includes data exploration, preprocessing, feature extraction, and model development for each model type (CNN, RNN, SVM).

## Results and Discussion
The project evaluates the performance of each model type in classifying emotions within audio data. Results indicate varying levels of success and highlight areas for improvement in each model.

## Future Directions
Future directions include refining the ensemble model, expanding the dataset through augmentation techniques, enhancing model interpretability, integrating user feedback mechanisms, and establishing a continuous evaluation framework.

## Limitations
Considerations are made regarding dataset representativeness, evaluation metrics, and capturing nuances in emotional expression.


## Team Acknowledgements
The successful completion of EMODEPICTOR is attributed to the collaborative efforts of the team members, each contributing expertise in various aspects of the project.

